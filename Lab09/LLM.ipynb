{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e93be455-d84a-43d1-b9e1-5dc5f22ed6c7",
   "metadata": {},
   "source": [
    "# Use LLMs to query Database - *Text-to-Query*\n",
    "\n",
    "This notebook demonstrates a simple workflow which uses **Vanna** to turn English sentences into SQL.\n",
    "\n",
    "Large Language Models (LLMs) are getting increasingly popular. It is now possible to generate web applications, create apps and manipulate large-scale data using models like ChatGPT, Google Bard, and DALL-E.\n",
    "\n",
    "It is now also possible to build a *Text-to-Query* system using Natural Language Processing (NLP) techniques. \n",
    "\n",
    "I will \n",
    "\n",
    "* briefly introduce the concept using **Venna** as an example\n",
    "* then move back to the created DuckDB table for a small demonstration\n",
    "* finally, I want to highlight the challenges and limitations of using such a technique in the data analytics field. \n",
    "                                                                            \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aa88e465-893d-4331-b64e-bef2864ba7e1",
   "metadata": {},
   "source": [
    "## Why **Venna**\n",
    "I select **Vanna** mainly for demonstration purposes. There are other solutions like  __[AWS + Claudev2](https://aws.amazon.com/blogs/machine-learning/build-a-robust-text-to-sql-solution-generating-complex-queries-self-correcting-and-querying-diverse-data-sources/)__ and __[LangChain](https://github.com/langchain-ai/langchain)__. The problem is they require API keys and they are not free. \n",
    "\n",
    "Vanna,  also requires an API key, including an OpenAI key, but it is available for free for at least one month.\n",
    "For more information about it please go to __[Venna.AI](https://vanna.ai/docs/postgres-openai-vanna-vannadb/)__\n",
    "Their GitHbub is __[https://github.com/vanna-ai/vanna](https://github.com/vanna-ai/vanna)__.\n",
    "Make sure you obtain your API key and model name according to \n",
    "* LLM = OpenAI via Vanna.AI (Recommended)\n",
    "* training data = Vanna Hosted Vector DB (Recommended)\n",
    "* Database = DuckDB\n",
    "\n",
    "\n",
    "![How Venna works](img/1_KZNioLcEiA0y-cYn-Astsg.webp)\n",
    "\n",
    "Now, let's look at how we query our listingGrpMonthly table using text.                                                                                                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c88936-c9bd-48e2-8463-9d8843d1da3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install vanna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43f6a66-1231-48f5-9ff7-74b656b823c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import vanna\n",
    "from vanna.remote import VannaDefault"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff4eabc-df34-42e1-bc60-ed8e8efdaee5",
   "metadata": {},
   "source": [
    "Here we create a default **Vanna** default model. \n",
    "To use the specific model you created online in previous step, you specify your api_key and model_name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bfa689-f957-477a-a7ee-c61328f7e0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# api_key = 'aa7f794af5d342d0a13c590204992cd0' # Your API key from https://vanna.ai/account/profile \n",
    "\n",
    "# vanna_model_name ='yang_test' # Your model name from https://vanna.ai/account/profile \n",
    "# vn = VannaDefault(model=vanna_model_name, api_key=api_key)\n",
    "\n",
    "api_key = '8dc7d7e14e354782a3ed9f7e638c138e' # Your API key from https://vanna.ai/account/profile \n",
    "vanna_model_name ='duckdbtutorial_yw' # Your model name from https://vanna.ai/account/profile \n",
    "vn = VannaDefault(model=vanna_model_name, api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1e7d53-d874-4a3b-9d1c-007cc94c179b",
   "metadata": {},
   "source": [
    "In case we mess up the database created in the previous step and demonstrate how you can retrieve extra data from another database. </br>\n",
    "Notice that we connect to a new database called 'dbtrain.db' first. </br>\n",
    "Then **Attach** the previous database, my_database3.db, and call it *duck*. </br>\n",
    "We **Create Table** *ListingIZMonthly* based on *listingGrpMonthly* in *duck*. </br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce49cd2-8b72-49c2-93d9-b0db9ddd2e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb as dd\n",
    "# con.close()\n",
    "con=dd.connect('my_database_exercise2.db')\n",
    "con.sql('SHOW TABLES;')\n",
    "con.sql(\"select count(*) from listingGrpMonthly\")\n",
    "# con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5eb6fa2-d60c-4e86-ada7-e234c0cd82e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb as dd\n",
    "con.close()\n",
    "con=dd.connect('dbtrain_exercise_2.db')\n",
    "con.sql('SHOW TABLES;')\n",
    "con.sql(\"\"\"SELECT database_name, path, type FROM duckdb_databases;\"\"\")\n",
    "\n",
    "con.sql(\"\"\"ATTACH 'duckdb:my_database_exercise2.db' AS duck;\"\"\")\n",
    "con.sql(\"\"\"SELECT database_name, path, type FROM duckdb_databases;\"\"\")\n",
    "\n",
    "con.sql(\"\"\"CREATE TABLE listingIZMonthly as FROM duck.listingGrpMonthly;\"\"\")\n",
    "con.sql(\"\"\"DETACH duck\"\"\")\n",
    "\n",
    "con.sql(\"\"\"show tables;\"\"\")\n",
    "con.sql(\"\"\"select * from listingIZMonthly\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25f6beb-8f87-4b2a-a503-e1e086bda4c7",
   "metadata": {},
   "source": [
    "Now, we can see in the new *dbtrain.db*, there is a new table called *ListingIZMonthly*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea051b0e-8090-4247-9014-4c1b7b3f31ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\"\"\"show tables;\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c95116-c45d-4be9-8f2d-31c75d13a8c5",
   "metadata": {},
   "source": [
    "Now, we are ready to build the model. First, we connect the dbtrain.db to our Vanna model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20192ada-fff1-4411-9d56-7ba7dfb43b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vn.connect_to_duckdb('dbtrain_exercise_2.db')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7d2182-9e35-49e5-9587-4e47dafd20c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\"\"\"show tables;\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a9daac-6370-4571-85e3-f145ea36e652",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\"\"\"select * from listingIZMonthly \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4613f4-d25a-4a3e-aeb2-799df85c6f00",
   "metadata": {},
   "source": [
    "After reminding us what is inside the *listingIZMonthly* table, we start to organize a key query which is used to retrieve information from the table. </br>\n",
    "We want to show the listing density at a monthly basis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9deab7ba-b7d6-4406-9c51-33e424a62a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql(\"\"\"\n",
    "select month, year, listingRatio, intermediateZone from listingIZMonthly\n",
    "where month='May' and year=2023\n",
    "order by listingRatio asc\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c3589c-6571-4396-9013-83876de71023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not needed as the table created in this way\n",
    "# con.sql(\"\"\"ALTER TABLE listingIZMonthly RENAME dm TO month;\"\"\")\n",
    "# con.sql(\"\"\"ALTER TABLE listingIZMonthly RENAME dy TO year;\"\"\")\n",
    "# con.sql(\"\"\"ALTER TABLE listingIZMonthly ADD COLUMN ratioOfListings FLOAT DEFAULT (listings/HH)*100;\"\"\")\n",
    "# con.sql(\"\"\"ALTER TABLE listingIZMonthly RENAME Name TO IntermediateZone;\"\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296a9812-e862-4eb3-875f-c84b81d2e6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vn.run_sql(\"SELECT * FROM INFORMATION_SCHEMA.COLUMNS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba12a8cf-eb2e-4719-acf8-c099dacf7646",
   "metadata": {},
   "source": [
    "The schema of the database is very simple. We decide to use it as the generic training plan. </br>\n",
    "If you have a very complicated schema, e.g. several tables with keys joining them, you may consider the part which is useful to the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd49436-f3d4-4929-9a56-613f70f848fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The information schema query may need some tweaking depending on your database. This is a good starting point.\n",
    "df_information_schema = vn.run_sql(\"SELECT * FROM INFORMATION_SCHEMA.COLUMNS\")\n",
    "\n",
    "# This will break up the information schema into bite-sized chunks that can be referenced by the LLM\n",
    "plan = vn.get_training_plan_generic(df_information_schema)\n",
    "plan\n",
    "\n",
    "# If you like the plan, then uncomment this and run it to train\n",
    "vn.train(plan=plan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62797499-ffd5-4c0b-bb4f-0c97daf6b6e0",
   "metadata": {},
   "source": [
    "Our main training data is the *listingIZMonthly* table which shall be passed as ddl."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dba6bf-82fc-4854-bd86-7e3d1c95b909",
   "metadata": {},
   "outputs": [],
   "source": [
    "vn.train(ddl=\"DESCRIBE SELECT * FROM listingIZMonthly;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df7607b-9a61-4d7d-ae16-de23b95ac7ca",
   "metadata": {},
   "source": [
    "We then create a text vs sql pair as the training set. \n",
    "This part is critical for the LLM to match the embeddings between text and sql sentences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3378c3e1-e9a9-4dda-8ac9-a75156409d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is an example of training on SQL statements\n",
    "# In the listing ratio query of listingIZMonthly table.\n",
    "vn.train(\n",
    "question=\"listingRatio in intermediateZone every month\"\n",
    ",sql=\"\"\"\n",
    "    select month, year, listingRatio, intermediateZone from listingIZMonthly\n",
    "    order by listingRatio asc\n",
    ";\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b023470b-76f9-42c7-b622-1e19c937f9c5",
   "metadata": {},
   "source": [
    "We also can add a document as another form of training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9ca3af-f7f3-4302-b4bf-df9d6ca09bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "vn.train(documentation=\"The ratio of listings in intermediate zones (IZs)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32527bf6-3963-4397-a142-61456389406e",
   "metadata": {},
   "source": [
    "After these simple training steps, we are ready to run our model.</br>\n",
    "We want to ask for some information about the listing ratio in different time frames and intermediate zones.</br\n",
    "You will see some details about the transformation of query and data.</br>\n",
    "An output is an SQL sentence the model generated based on the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc752170-4720-4ea5-a227-bb934717f6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vn.ask(\"Which intermediateZone had the highest listingRatio in 2020? what is the month?\", visualize=False, allow_llm_to_see_data=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148e3eac-aa30-4c0a-85f2-ddfd798daf66",
   "metadata": {},
   "source": [
    "We can execute the query in DuckDB to see if the result is correct. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4475c5b7-45b7-4046-8557-efa4c330f18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# con.sql(\"\"\"\n",
    "# SELECT listingRatio,intermediateZone, year, month\n",
    "# FROM listingIZMonthly\n",
    "# where year=2021\n",
    "# ORDER BY listingRatio \n",
    "# ;\n",
    "# \"\"\")\n",
    "# LIMIT 1;\n",
    "\n",
    "con.sql(\"\"\"\n",
    "select intermediateZone, month, max(listingRatio) as highestListingRatio\n",
    "from listingIZMonthly\n",
    "where year = 2020\n",
    "group by intermediateZone, month\n",
    "order by highestListingRatio desc\n",
    "limit 1;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5520425d-b8d6-4975-bc97-f3c41b8a86a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vanna.flask import VannaFlaskApp\n",
    "app = VannaFlaskApp(vn)\n",
    "app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232e1cbe-da82-4a93-b117-75da1bef643d",
   "metadata": {},
   "source": [
    "# Some final reflections\n",
    "We demonstrated how databases can be queried by plain language questions through Text-to-Query technique.  </b>\n",
    "This technique is still developing along with LLMs.  </b>\n",
    "Before considering using these models, you also need to know the challenges and limitations. </b>\n",
    "\n",
    "* Hallucinations </br>\n",
    "A model generates output that is not based on the provided context or facts. For text-to-SQL tasks, this means the system creates SQL queries referencing non-existent columns, tables, or filters.</br>\n",
    "The latest techniques to fix this include clarifying schema, Retrieval-Augmented Generation (RAG), Reasoning + Acting (ReAct) and Chain of Thought (CoT), etc.</b>\n",
    "\n",
    "* Preformance </br>\n",
    "Different SQL queries can produce the same result. This leads to challenges in calculating the efficiency of AI-generated SQL. </br>\n",
    "Query large databases easily increase unexpected costs to use LLMs. \n",
    "Hard to implement models in multi-disciplinary teams, e.g directly use spatial joins in the example. \n",
    "\n",
    "* Security </br>\n",
    "Generating SQL from NLP often requires access to the local data, e.g. 'allow_llm_to_see_data' in Vanna. </br>\n",
    "Using public LLM is not an option. Running a local LLM also comprises security. LLM can be manipulated to reveal sensitive user information. \n",
    "\n",
    "Now, it is your turn for some exercise. </b>\n",
    "Please \n",
    "* use the explore different training data based on **listing per KM area** for each intermediate zone per month year;\n",
    "* try spatial SQLs if you have time;\n",
    "* Anyone wants to try vectorDB? \n",
    "\n",
    "## Reference \n",
    "https://medium.com/wrenai/reducing-hallucinations-in-text-to-sql-building-trust-and-accuracy-in-data-access-176ac636e208 </br>\n",
    "    \n",
    "https://medium.com/wrenai/reducing-hallucinations-in-text-to-sql-building-trust-and-accuracy-in-data-access-176ac636e208 </b>\n",
    "\n",
    "https://www.k2view.com/blog/llm-text-to-sql/#Reducing-the-risks-of-LLM-text-to-SQL-models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
